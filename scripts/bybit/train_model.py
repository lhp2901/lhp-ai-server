import os
import pandas as pd
import numpy as np
from supabase import create_client, Client
from dotenv import load_dotenv
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import joblib

# ===== 1. Load biáº¿n mÃ´i trÆ°á»ng & káº¿t ná»‘i Supabase =====
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_ROLE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)

# ===== 2. Láº¥y dá»¯ liá»‡u huáº¥n luyá»‡n tá»« Supabase =====
def fetch_training_data(symbols=None):
    print("ğŸ“¥ Äang táº£i dá»¯ liá»‡u huáº¥n luyá»‡n tá»« Supabase...")
    try:
        query = supabase.table("training_dataset").select("*")
        if symbols:
            query = query.in_("symbol", symbols)
        res = query.execute()
        if not res.data:
            raise Exception("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u training.")
        return pd.DataFrame(res.data)
    except Exception as e:
        raise Exception(f"âŒ Lá»—i khi táº£i dá»¯ liá»‡u training: {e}")

# ===== 3. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u =====
def preprocess(df: pd.DataFrame):
    if 'signal' not in df.columns:
        raise Exception("âš ï¸ Dá»¯ liá»‡u khÃ´ng chá»©a cá»™t 'signal'.")

    drop_cols = ['id', 'symbol', 'created_at', 'target', 'signal']
    X = df.drop(columns=drop_cols, errors='ignore')

    # Xá»­ lÃ½ Ä‘áº·c trÆ°ng
    X = X.apply(pd.to_numeric, errors='coerce')
    X = X.replace([np.inf, -np.inf], np.nan)
    X.dropna(inplace=True)

    # ğŸ¯ Dá»¯ liá»‡u Ä‘áº§u ra
    y = df.loc[X.index, 'signal'].astype(int)

    print(f"ğŸ“Š Dá»¯ liá»‡u Ä‘áº§u vÃ o X shape: {X.shape}")
    print(f"ğŸ¯ CÃ¡c nhÃ£n y duy nháº¥t: {y.unique()}")

    return X, y

# ===== 4. Huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest =====
def train_model(X_train, y_train):
    print("ğŸ§  Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest...")
    model = RandomForestClassifier(
        n_estimators=200,
        max_depth=10,
        random_state=42,
        n_jobs=-1,
        class_weight='balanced'
    )
    model.fit(X_train, y_train)
    return model

# ===== 5. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh =====
def evaluate_model(model, X_test, y_test):
    print("\n=== ğŸ“Š ÄÃNH GIÃ MÃ” HÃŒNH ===")
    preds = model.predict(X_test)

    print(classification_report(
        y_test, preds,
        target_names=['SELL (-1)', 'HOLD (0)', 'BUY (1)'],
        labels=[-1, 0, 1]
    ))

    acc = accuracy_score(y_test, preds)
    print(f"ğŸ¯ Accuracy: {acc:.4f}")

    print("ğŸ§© Confusion Matrix:")
    print(confusion_matrix(y_test, preds, labels=[-1, 0, 1]))

# ===== 6. LÆ°u mÃ´ hÃ¬nh ra file .pkl =====
def save_model(model, path="model/model_rf.pkl"):
    try:
        joblib.dump(model, path)
        print(f"âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {path}")
    except Exception as e:
        print(f"âŒ Lá»—i khi lÆ°u mÃ´ hÃ¬nh: {e}")

# ===== 7. Cháº¡y pipeline huáº¥n luyá»‡n =====
def run():
    symbols = None  # VÃ­ dá»¥: ['BTCUSDT', 'ETHUSDT']
    df = fetch_training_data(symbols)
    print(f"ğŸ“Š Tá»•ng sá»‘ dÃ²ng dá»¯ liá»‡u huáº¥n luyá»‡n: {len(df)}")

    X, y = preprocess(df)

    print("ğŸ”€ Äang chia dá»¯ liá»‡u 80/20 cho train/test...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )

    model = train_model(X_train, y_train)
    evaluate_model(model, X_test, y_test)
    save_model(model)

# ===== 8. Entry Point =====
if __name__ == "__main__":
    run()
